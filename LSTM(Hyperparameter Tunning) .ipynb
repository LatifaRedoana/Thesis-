{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb718549-bf47-4af6-9205-8435ebaa36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,date,timedelta\n",
    "\n",
    "\n",
    "# Machine Learning - Scikit-learn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit, ParameterGrid, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import  MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "# Deep Learning - TensorFlow and Keras\n",
    "import keras\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "\n",
    "#Grid search \n",
    "import itertools\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "885fae73-8b5c-4b55-80e5-41ac2e3b9929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            weighted_sum\n",
      "2020-02-01    239.210369\n",
      "2020-02-02     28.280318\n",
      "2020-02-03    199.366981\n",
      "2020-02-04    423.067131\n",
      "2020-02-05    409.692107\n",
      "...                  ...\n",
      "2023-12-02    114.049422\n",
      "2023-12-03      0.000000\n",
      "2023-12-04    226.893157\n",
      "2023-12-05    390.659238\n",
      "2023-12-06    425.322937\n",
      "\n",
      "[1328 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>294.511578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164.458734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>149.168497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>356.291042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>428.762568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weighted_sum\n",
       "count   1328.000000\n",
       "mean     294.511578\n",
       "std      164.458734\n",
       "min        0.000000\n",
       "25%      149.168497\n",
       "50%      356.291042\n",
       "75%      428.762568\n",
       "max      570.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readin the data set kepping date as index\n",
    "df=pd.read_csv('weighted_sum.csv')\n",
    "\n",
    "# Make the 'date' column as index of the DataFrame\n",
    "df.index = df[\"date\"].values\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df.drop(columns='date', inplace=True)\n",
    "\n",
    "# Reindexing DataFrame with pd.date_range, ensure df spans a specified period, filling in any gaps with NaN values.\n",
    "idx = pd.date_range('2019-10-24', '2023-12-06')\n",
    "\n",
    "df = df.reindex(idx)\n",
    "\n",
    "# filter out the specified data range contaning zero\n",
    "df=df.drop(df.loc['2023-05-12':'2023-07-27'].index)\n",
    "\n",
    "# Filter out the initial date range considering machine unstability\n",
    "df=df.drop(df.loc['2019-10-24':'2020-01-31'].index)\n",
    "\n",
    "\n",
    "rows_to_fill = np.where(df[\"weighted_sum\"].isna())\n",
    "\n",
    "for row in rows_to_fill:\n",
    "\n",
    "    df.iloc[row] = df.iloc[row + 7]\n",
    "\n",
    "# Replace negative values with zero in 'weighted_sum'\n",
    "df['weighted_sum'] = df['weighted_sum'].clip(lower=0)\n",
    "\n",
    "# replace 7 irregular data points with 8th highest value.\n",
    "df[df['weighted_sum']>570]=570\n",
    "\n",
    "print(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f02294-9ebd-4cd5-becf-184c051b26aa",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d252a1f-46a8-43ec-8544-0421093b9ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            weighted_sum\n",
      "2020-02-01    239.210369\n",
      "2020-02-02     28.280318\n",
      "2020-02-03    199.366981\n",
      "2020-02-04    423.067131\n",
      "2020-02-05    409.692107\n",
      "...                  ...\n",
      "2022-08-13    114.743957\n",
      "2022-08-14      0.000000\n",
      "2022-08-15    273.145554\n",
      "2022-08-16    382.488038\n",
      "2022-08-17    276.267078\n",
      "\n",
      "[929 rows x 1 columns]             weighted_sum\n",
      "2022-08-18    193.901423\n",
      "2022-08-19    432.053452\n",
      "2022-08-20    134.239967\n",
      "2022-08-21      0.000000\n",
      "2022-08-22    293.099946\n",
      "...                  ...\n",
      "2023-12-02    114.049422\n",
      "2023-12-03      0.000000\n",
      "2023-12-04    226.893157\n",
      "2023-12-05    390.659238\n",
      "2023-12-06    425.322937\n",
      "\n",
      "[399 rows x 1 columns]             weighted_sum\n",
      "2020-02-01    239.210369\n",
      "2020-02-02     28.280318\n",
      "2020-02-03    199.366981\n",
      "2020-02-04    423.067131\n",
      "2020-02-05    409.692107\n",
      "...                  ...\n",
      "2021-11-07      0.000000\n",
      "2021-11-08    128.806820\n",
      "2021-11-09    416.624904\n",
      "2021-11-10    436.489289\n",
      "2021-11-11    444.859699\n",
      "\n",
      "[650 rows x 1 columns]             weighted_sum\n",
      "2021-11-12    393.986012\n",
      "2021-11-13    134.879826\n",
      "2021-11-14      0.000000\n",
      "2021-11-15    390.718951\n",
      "2021-11-16    460.146419\n",
      "...                  ...\n",
      "2022-08-13    114.743957\n",
      "2022-08-14      0.000000\n",
      "2022-08-15    273.145554\n",
      "2022-08-16    382.488038\n",
      "2022-08-17    276.267078\n",
      "\n",
      "[279 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the train-test split parameters (70:30)\n",
    "initial_train_size = int(0.7 * len(df)) # Start with 70% training data\n",
    "initial_train_data= df[:initial_train_size]\n",
    "initial_test_data=df[initial_train_size:]\n",
    "\n",
    "\n",
    "# Now, split the initial training data into 70% training and 30% validation\n",
    "train_size = int(0.7 * len(initial_train_data))\n",
    "train_data=initial_train_data[:train_size]\n",
    "validation_set = initial_train_data[train_size:]\n",
    "\n",
    "print(initial_train_data, initial_test_data , train_data ,validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde5ee7-9f11-4d69-a6b0-f7f19874a45e",
   "metadata": {},
   "source": [
    "#### Create lstm model function, create function for transforming data to supervised learning and define tuning parameter space for lstm model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3508a2c-6de0-402d-bebb-993844d395ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of combination:192\n",
      "Split size:64.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize parameters\n",
    "time_step = 1\n",
    "features = 1\n",
    "\n",
    "# Build a function for the LSTM model\n",
    "def create_lstm_model(n_layers, n_neurons, dropout_rate, time_step):\n",
    "    model = Sequential()\n",
    "    model.add(keras.Input(shape=(time_step, features)))\n",
    "    model.add(LSTM(n_neurons, activation='relu',return_sequences=True))\n",
    "    model.add(LSTM(n_neurons,  dropout=dropout_rate, activation='relu'))\n",
    "    model.add(Dense(1)) \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['root_mean_squared_error'])\n",
    "    return model \n",
    "\n",
    "\n",
    "# function to Transform Data to Supervised Learning Format\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        dataX.append(dataset.iloc[i:(i + time_step), 0])  # Corrected indexing for Pandas\n",
    "        dataY.append(dataset.iloc[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Now, split the initial training data into 70% training and 30% validation\n",
    "train_size = int(0.7 * len(initial_train_data))  # 70% of the initial train size\n",
    "train_data = initial_train_data[:train_size]  # 70% for actual training\n",
    "test_data = initial_train_data[train_size:]  # Remaining 30% for validation\n",
    "\n",
    "# Transform to supervised learning\n",
    "X_train, y_train = create_dataset(train_data, time_step=time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step=time_step)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features] for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_layers': [2, 3, 4, 5],\n",
    "    'n_neurons': [10, 20, 50, 100],\n",
    "    'dropout_rate': [0.0, 0.1, 0.5],\n",
    "    'time_step': [1, 7, 14, 30]\n",
    "}\n",
    "\n",
    "# Initialize variables to store the best model and the lowest RMSE\n",
    "best_rmse = float('inf')  # Start with a very high value for RMSE\n",
    "best_model = None\n",
    "best_params = None\n",
    "best_iteration= None\n",
    "\n",
    "# total number of combinations\n",
    "total_combinations= len(list(itertools.product(*param_grid.values())))\n",
    "print(f'Total number of combination:{total_combinations}')\n",
    "\n",
    "# define the number of split\n",
    "num_splits =3\n",
    "split_size=total_combinations/num_splits\n",
    "print(f'Split size:{split_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525dc5b3-de93-46b7-9732-85db108fbaca",
   "metadata": {},
   "source": [
    "### We split the total combination of parameter in three equal parts to execute reducing running complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460f8368-566b-44cf-9aea-5e45c085713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First split:\n",
      "Iteration 1: 2 layers, 10 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "RMSE for current model: 169.87734745394823\n",
      "Iteration 2: 2 layers, 10 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 101.52814145860907\n",
      "Iteration 3: 2 layers, 10 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 101.82280778071348\n",
      "Iteration 4: 2 layers, 10 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 162.8440214046701\n",
      "Iteration 5: 2 layers, 10 neurons, 0.1 dropout, 1 time steps.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x165872660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 166.27531126293442\n",
      "Iteration 6: 2 layers, 10 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 115.44658368343086\n",
      "Iteration 7: 2 layers, 10 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 118.21863830062684\n",
      "Iteration 8: 2 layers, 10 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 159.56762981789555\n",
      "Iteration 9: 2 layers, 10 neurons, 0.5 dropout, 1 time steps.\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x167fa8cc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 216.07111203000346\n",
      "Iteration 10: 2 layers, 10 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 195.42633334057908\n",
      "Iteration 11: 2 layers, 10 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 200.3233973826623\n",
      "Iteration 12: 2 layers, 10 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 223.06420531496354\n",
      "Iteration 13: 2 layers, 20 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\n",
      "RMSE for current model: 161.4113951798401\n",
      "Iteration 14: 2 layers, 20 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 94.41846683887167\n",
      "Iteration 15: 2 layers, 20 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 125.64842029059898\n",
      "Iteration 16: 2 layers, 20 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 174.4884727464645\n",
      "Iteration 17: 2 layers, 20 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 162.97243764546533\n",
      "Iteration 18: 2 layers, 20 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "RMSE for current model: 100.18506448690401\n",
      "Iteration 19: 2 layers, 20 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 151.1321247365004\n",
      "Iteration 20: 2 layers, 20 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "RMSE for current model: 191.9244275499959\n",
      "Iteration 21: 2 layers, 20 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 209.28129166643274\n",
      "Iteration 22: 2 layers, 20 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 165.6641730392595\n",
      "Iteration 23: 2 layers, 20 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 204.5393059239636\n",
      "Iteration 24: 2 layers, 20 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 326.6584118731165\n",
      "Iteration 25: 2 layers, 50 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "RMSE for current model: 155.26306961213083\n",
      "Iteration 26: 2 layers, 50 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 92.38993939143742\n",
      "Iteration 27: 2 layers, 50 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 145.62248170821903\n",
      "Iteration 28: 2 layers, 50 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 160.84602319914697\n",
      "Iteration 29: 2 layers, 50 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 155.10680106647092\n",
      "Iteration 30: 2 layers, 50 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 89.20305677466463\n",
      "Iteration 31: 2 layers, 50 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 112.76038353658423\n",
      "Iteration 32: 2 layers, 50 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 174.6185266353755\n",
      "Iteration 33: 2 layers, 50 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "RMSE for current model: 178.87390146644756\n",
      "Iteration 34: 2 layers, 50 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 159.96210711365262\n",
      "Iteration 35: 2 layers, 50 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 181.50283929478223\n",
      "Iteration 36: 2 layers, 50 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 233.37930100915455\n",
      "Iteration 37: 2 layers, 100 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 150.58202961956883\n",
      "Iteration 38: 2 layers, 100 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 92.85172622110133\n",
      "Iteration 39: 2 layers, 100 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 123.63472998962467\n",
      "Iteration 40: 2 layers, 100 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "RMSE for current model: 203.2156620697088\n",
      "Iteration 41: 2 layers, 100 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 149.32704030221763\n",
      "Iteration 42: 2 layers, 100 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 96.69393391233528\n",
      "Iteration 43: 2 layers, 100 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "RMSE for current model: 98.92673914478264\n",
      "Iteration 44: 2 layers, 100 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "RMSE for current model: 188.0570619153146\n",
      "Iteration 45: 2 layers, 100 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 167.05110612126967\n",
      "Iteration 46: 2 layers, 100 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 159.37388324085958\n",
      "Iteration 47: 2 layers, 100 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 156.83566673041062\n",
      "Iteration 48: 2 layers, 100 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "RMSE for current model: 497.8222918557617\n",
      "Iteration 49: 3 layers, 10 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 159.18204585024426\n",
      "Iteration 50: 3 layers, 10 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 106.4226077963018\n",
      "Iteration 51: 3 layers, 10 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 143.23837320493737\n",
      "Iteration 52: 3 layers, 10 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 158.63682699966742\n",
      "Iteration 53: 3 layers, 10 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 177.60769952295533\n",
      "Iteration 54: 3 layers, 10 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 108.30873597332726\n",
      "Iteration 55: 3 layers, 10 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 147.04493218660835\n",
      "Iteration 56: 3 layers, 10 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\n",
      "RMSE for current model: 174.60139022537945\n",
      "Iteration 57: 3 layers, 10 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 223.88093553846463\n",
      "Iteration 58: 3 layers, 10 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 182.98644492666827\n",
      "Iteration 59: 3 layers, 10 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\n",
      "RMSE for current model: 211.5314687574117\n",
      "Iteration 60: 3 layers, 10 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 327.07087886406276\n",
      "Iteration 61: 3 layers, 20 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "RMSE for current model: 158.571060815462\n",
      "Iteration 62: 3 layers, 20 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 101.52972966386255\n",
      "Iteration 63: 3 layers, 20 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 202.2531301722948\n",
      "Iteration 64: 3 layers, 20 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "RMSE for current model: 163.8696759053196\n",
      "\n",
      "Best model found in Iteration: 30\n",
      "\n",
      "Best model RMSE: 89.20305677466463\n",
      "\n",
      "Best parameters: Layers=2, Neurons=50, Dropout=0.1, Time step=7\n"
     ]
    }
   ],
   "source": [
    "# first split(i=1 to 64)\n",
    "\n",
    "print('\\nFirst split:')\n",
    "for i, params in enumerate(itertools.product(*param_grid.values()), start=1):\n",
    "    if i > split_size:\n",
    "        break\n",
    "    n_layers, n_neurons, dropout_rate, time_step = params  # Unpack the parameters\n",
    "    \n",
    "    print(f\"Iteration {i}: {n_layers} layers, {n_neurons} neurons, {dropout_rate} dropout, {time_step} time steps.\")\n",
    "    \n",
    "    # Transform to supervised learning\n",
    "    X_train, y_train = create_dataset(train_data, time_step=time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step=time_step)\n",
    "    \n",
    "    # Reshape input to be [samples, time steps, features] for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "        \n",
    "    # Create your LSTM model with the current parameter combination\n",
    "    model = create_lstm_model(n_layers=n_layers, n_neurons=n_neurons, dropout_rate=dropout_rate, time_step=time_step)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=False)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Reshape y_pred to be 1D for RMSE calculation\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"\\nRMSE for current model: {rmse}\")\n",
    "    \n",
    "    # Update best model if the current one is better\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        best_iteration=i\n",
    "\n",
    "# Output the best model and parameters\n",
    "print(f'\\nBest model found in Iteration: {best_iteration}')\n",
    "print(f\"\\nBest model RMSE: {best_rmse}\")\n",
    "print(f\"\\nBest parameters: Layers={best_params[0]}, Neurons={best_params[1]}, Dropout={best_params[2]}, Time step={best_params[3]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "742488a0-a232-4613-abf0-c9cf7e6eb0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second split:\n",
      "\n",
      "Iteration 65: 3 layers, 20 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 161.11560492378376\n",
      "\n",
      "Iteration 66: 3 layers, 20 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 104.46573043874612\n",
      "\n",
      "Iteration 67: 3 layers, 20 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 146.52803772281413\n",
      "\n",
      "Iteration 68: 3 layers, 20 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 180.9519356120199\n",
      "\n",
      "Iteration 69: 3 layers, 20 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "RMSE for current model: 191.99443728364406\n",
      "\n",
      "Iteration 70: 3 layers, 20 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 163.0669769964339\n",
      "\n",
      "Iteration 71: 3 layers, 20 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 192.16610247573664\n",
      "\n",
      "Iteration 72: 3 layers, 20 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 225.63659705020288\n",
      "\n",
      "Iteration 73: 3 layers, 50 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\n",
      "RMSE for current model: 153.60153572184447\n",
      "\n",
      "Iteration 74: 3 layers, 50 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "RMSE for current model: 103.50352113330044\n",
      "\n",
      "Iteration 75: 3 layers, 50 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 135.82060933022711\n",
      "\n",
      "Iteration 76: 3 layers, 50 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "RMSE for current model: 159.73506746209475\n",
      "\n",
      "Iteration 77: 3 layers, 50 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "RMSE for current model: 153.7527859589815\n",
      "\n",
      "Iteration 78: 3 layers, 50 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 94.9388977052513\n",
      "\n",
      "Iteration 79: 3 layers, 50 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "\n",
      "RMSE for current model: 100.55558319152883\n",
      "\n",
      "Iteration 80: 3 layers, 50 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 184.74092877505572\n",
      "\n",
      "Iteration 81: 3 layers, 50 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 199.6763754615284\n",
      "\n",
      "Iteration 82: 3 layers, 50 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 143.7887981869388\n",
      "\n",
      "Iteration 83: 3 layers, 50 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 192.4076266002568\n",
      "\n",
      "Iteration 84: 3 layers, 50 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 3882.5682377470966\n",
      "\n",
      "Iteration 85: 3 layers, 100 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\n",
      "RMSE for current model: 148.5226856675161\n",
      "\n",
      "Iteration 86: 3 layers, 100 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 99.72959537019713\n",
      "\n",
      "Iteration 87: 3 layers, 100 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 105.26662697901703\n",
      "\n",
      "Iteration 88: 3 layers, 100 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "RMSE for current model: 210.51767820882233\n",
      "\n",
      "Iteration 89: 3 layers, 100 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 149.52600611058193\n",
      "\n",
      "Iteration 90: 3 layers, 100 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 93.70362512074722\n",
      "\n",
      "Iteration 91: 3 layers, 100 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 99.17515757928804\n",
      "\n",
      "Iteration 92: 3 layers, 100 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\n",
      "RMSE for current model: 289.383289267923\n",
      "\n",
      "Iteration 93: 3 layers, 100 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 164.1139012781938\n",
      "\n",
      "Iteration 94: 3 layers, 100 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 167.38654510827962\n",
      "\n",
      "Iteration 95: 3 layers, 100 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "RMSE for current model: 182.72978913191173\n",
      "\n",
      "Iteration 96: 3 layers, 100 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\n",
      "RMSE for current model: 278.62712801293975\n",
      "\n",
      "Iteration 97: 4 layers, 10 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "RMSE for current model: 172.35311924424846\n",
      "\n",
      "Iteration 98: 4 layers, 10 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 95.75048353899896\n",
      "\n",
      "Iteration 99: 4 layers, 10 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 151.98383361510716\n",
      "\n",
      "Iteration 100: 4 layers, 10 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 179.75924511874967\n",
      "\n",
      "Iteration 101: 4 layers, 10 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "RMSE for current model: 164.0600694461077\n",
      "\n",
      "Iteration 102: 4 layers, 10 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 112.74854852480883\n",
      "\n",
      "Iteration 103: 4 layers, 10 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 158.7599364968538\n",
      "\n",
      "Iteration 104: 4 layers, 10 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 156.0632736109412\n",
      "\n",
      "Iteration 105: 4 layers, 10 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\n",
      "RMSE for current model: 207.59550516430994\n",
      "\n",
      "Iteration 106: 4 layers, 10 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "\n",
      "RMSE for current model: 134.8751464647175\n",
      "\n",
      "Iteration 107: 4 layers, 10 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 218.35876114228518\n",
      "\n",
      "Iteration 108: 4 layers, 10 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 227.08385130565136\n",
      "\n",
      "Iteration 109: 4 layers, 20 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 160.16905985650675\n",
      "\n",
      "Iteration 110: 4 layers, 20 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 89.13209881401892\n",
      "\n",
      "Iteration 111: 4 layers, 20 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 129.69859433337874\n",
      "\n",
      "Iteration 112: 4 layers, 20 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 139.85902076966957\n",
      "\n",
      "Iteration 113: 4 layers, 20 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 159.4572454084331\n",
      "\n",
      "Iteration 114: 4 layers, 20 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 108.44963404317889\n",
      "\n",
      "Iteration 115: 4 layers, 20 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 98.3641588726403\n",
      "\n",
      "Iteration 116: 4 layers, 20 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "RMSE for current model: 172.25596322754686\n",
      "\n",
      "Iteration 117: 4 layers, 20 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 208.83479618523162\n",
      "\n",
      "Iteration 118: 4 layers, 20 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      "RMSE for current model: 178.09504091014338\n",
      "\n",
      "Iteration 119: 4 layers, 20 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 222.55931660158782\n",
      "\n",
      "Iteration 120: 4 layers, 20 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 235.61237071306695\n",
      "\n",
      "Iteration 121: 4 layers, 50 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 156.1113949398145\n",
      "\n",
      "Iteration 122: 4 layers, 50 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 95.83171300218198\n",
      "\n",
      "Iteration 123: 4 layers, 50 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 90.17153314652518\n",
      "\n",
      "Iteration 124: 4 layers, 50 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 179.71272663685346\n",
      "\n",
      "Iteration 125: 4 layers, 50 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 154.7327507408899\n",
      "\n",
      "Iteration 126: 4 layers, 50 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 90.22642107862463\n",
      "\n",
      "Iteration 127: 4 layers, 50 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 132.354407881497\n",
      "\n",
      "Iteration 128: 4 layers, 50 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "RMSE for current model: 285.9609653175781\n",
      "\n",
      "Best model RMSE: 89.13209881401892\n",
      "\n",
      "Best parameters: Layers=4, Neurons=20, Dropout=0.0, Time step=7\n",
      "\n",
      "Best model found in Iteration: 110\n"
     ]
    }
   ],
   "source": [
    "# second split(i= 65 to 128)\n",
    "\n",
    "print('\\nSecond split:')\n",
    "for i, params in enumerate (itertools.product(*param_grid.values()), start=1):\n",
    "    if i<= split_size: # Continue to the next iteration until i > 64\n",
    "        continue\n",
    "\n",
    "    if i > 2*split_size: \n",
    "        break   \n",
    "    n_layers, n_neurons, dropout_rate, time_step = params  # Unpack the parameters\n",
    "    \n",
    "    # Print iteration number, parameter combination, and total combinations\n",
    "    print(f\"\\nIteration {i}: {n_layers} layers, {n_neurons} neurons, {dropout_rate} dropout, {time_step} time steps.\")\n",
    "    \n",
    "    # Transform to supervised learning\n",
    "    X_train, y_train = create_dataset(train_data, time_step=time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step=time_step)\n",
    "    \n",
    "    # Reshape input to be [samples, time steps, features] for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    # Create your LSTM model with the current parameter combination\n",
    "    model = create_lstm_model(n_layers=n_layers, n_neurons=n_neurons, dropout_rate=dropout_rate, time_step=time_step)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=False)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Reshape y_pred to be 1D for RMSE calculation\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"\\nRMSE for current model: {rmse}\")\n",
    "    \n",
    "    # Update the best model \n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        best_iteration = i\n",
    "\n",
    "# Output the best model and parameters\n",
    "print(f\"\\nBest model RMSE: {best_rmse}\")\n",
    "print(f\"\\nBest parameters: Layers={best_params[0]}, Neurons={best_params[1]}, Dropout={best_params[2]}, Time step={best_params[3]}\")\n",
    "print(f'\\nBest model found in Iteration: {best_iteration}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac0018da-eebf-4bd1-943b-c9d12fc2a4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Third split\n",
      "\n",
      "Iteration 129: 4 layers, 50 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 197.9824438025524\n",
      "\n",
      "Iteration 130: 4 layers, 50 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 169.01118191053186\n",
      "\n",
      "Iteration 131: 4 layers, 50 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 173.8722172373733\n",
      "\n",
      "Iteration 132: 4 layers, 50 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 188.2651719567988\n",
      "\n",
      "Iteration 133: 4 layers, 100 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "RMSE for current model: 150.81468005243715\n",
      "\n",
      "Iteration 134: 4 layers, 100 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 91.62673538609162\n",
      "\n",
      "Iteration 135: 4 layers, 100 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 96.26687384481106\n",
      "\n",
      "Iteration 136: 4 layers, 100 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 163.04712180123477\n",
      "\n",
      "Iteration 137: 4 layers, 100 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 147.14569839651864\n",
      "\n",
      "Iteration 138: 4 layers, 100 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 90.79379817887846\n",
      "\n",
      "Iteration 139: 4 layers, 100 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 92.71788649553332\n",
      "\n",
      "Iteration 140: 4 layers, 100 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\n",
      "RMSE for current model: 203.33966985762146\n",
      "\n",
      "Iteration 141: 4 layers, 100 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 180.88479120723954\n",
      "\n",
      "Iteration 142: 4 layers, 100 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 156.52366038237025\n",
      "\n",
      "Iteration 143: 4 layers, 100 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 179.4556155959816\n",
      "\n",
      "Iteration 144: 4 layers, 100 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "RMSE for current model: 232.50424951515433\n",
      "\n",
      "Iteration 145: 5 layers, 10 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 161.9955441650533\n",
      "\n",
      "Iteration 146: 5 layers, 10 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 106.01131378942151\n",
      "\n",
      "Iteration 147: 5 layers, 10 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "RMSE for current model: 126.52128243546223\n",
      "\n",
      "Iteration 148: 5 layers, 10 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 195.97126337881764\n",
      "\n",
      "Iteration 149: 5 layers, 10 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\n",
      "RMSE for current model: 164.41706818314768\n",
      "\n",
      "Iteration 150: 5 layers, 10 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 118.38635098499229\n",
      "\n",
      "Iteration 151: 5 layers, 10 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 174.3792810065623\n",
      "\n",
      "Iteration 152: 5 layers, 10 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 169.10583215170286\n",
      "\n",
      "Iteration 153: 5 layers, 10 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 218.46927478000285\n",
      "\n",
      "Iteration 154: 5 layers, 10 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 184.90677897327834\n",
      "\n",
      "Iteration 155: 5 layers, 10 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "RMSE for current model: 231.76167232395477\n",
      "\n",
      "Iteration 156: 5 layers, 10 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 319.40521213085856\n",
      "\n",
      "Iteration 157: 5 layers, 20 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\n",
      "RMSE for current model: 161.5686828980313\n",
      "\n",
      "Iteration 158: 5 layers, 20 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\n",
      "RMSE for current model: 99.34017134787233\n",
      "\n",
      "Iteration 159: 5 layers, 20 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 109.63983377524109\n",
      "\n",
      "Iteration 160: 5 layers, 20 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 142.55015012143193\n",
      "\n",
      "Iteration 161: 5 layers, 20 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "RMSE for current model: 159.67248196994836\n",
      "\n",
      "Iteration 162: 5 layers, 20 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 108.67799889762166\n",
      "\n",
      "Iteration 163: 5 layers, 20 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 102.12454019361081\n",
      "\n",
      "Iteration 164: 5 layers, 20 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "RMSE for current model: 293.32729734115924\n",
      "\n",
      "Iteration 165: 5 layers, 20 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n",
      "\n",
      "RMSE for current model: 209.73072849331066\n",
      "\n",
      "Iteration 166: 5 layers, 20 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step\n",
      "\n",
      "RMSE for current model: 194.41115433045624\n",
      "\n",
      "Iteration 167: 5 layers, 20 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step\n",
      "\n",
      "RMSE for current model: 222.59953886165286\n",
      "\n",
      "Iteration 168: 5 layers, 20 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step\n",
      "\n",
      "RMSE for current model: 212.54280088723027\n",
      "\n",
      "Iteration 169: 5 layers, 50 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
      "\n",
      "RMSE for current model: 154.42328581486294\n",
      "\n",
      "Iteration 170: 5 layers, 50 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step\n",
      "\n",
      "RMSE for current model: 110.36515044700673\n",
      "\n",
      "Iteration 171: 5 layers, 50 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
      "\n",
      "RMSE for current model: 98.12200777860784\n",
      "\n",
      "Iteration 172: 5 layers, 50 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "RMSE for current model: 160.45832413189316\n",
      "\n",
      "Iteration 173: 5 layers, 50 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 156.73022185212892\n",
      "\n",
      "Iteration 174: 5 layers, 50 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 98.87625210575104\n",
      "\n",
      "Iteration 175: 5 layers, 50 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 97.68056516594109\n",
      "\n",
      "Iteration 176: 5 layers, 50 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\n",
      "RMSE for current model: 288.10572245635075\n",
      "\n",
      "Iteration 177: 5 layers, 50 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 199.39937404147452\n",
      "\n",
      "Iteration 178: 5 layers, 50 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 166.04054225096868\n",
      "\n",
      "Iteration 179: 5 layers, 50 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 217.77508231051166\n",
      "\n",
      "Iteration 180: 5 layers, 50 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "RMSE for current model: 306.6809405711797\n",
      "\n",
      "Iteration 181: 5 layers, 100 neurons, 0.0 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "RMSE for current model: 150.55986549363843\n",
      "\n",
      "Iteration 182: 5 layers, 100 neurons, 0.0 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "RMSE for current model: 91.24366044971488\n",
      "\n",
      "Iteration 183: 5 layers, 100 neurons, 0.0 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "RMSE for current model: 99.64468517249496\n",
      "\n",
      "Iteration 184: 5 layers, 100 neurons, 0.0 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "RMSE for current model: 174.390317815554\n",
      "\n",
      "Iteration 185: 5 layers, 100 neurons, 0.1 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "RMSE for current model: 151.69640087978638\n",
      "\n",
      "Iteration 186: 5 layers, 100 neurons, 0.1 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "RMSE for current model: 85.51766536365764\n",
      "\n",
      "Iteration 187: 5 layers, 100 neurons, 0.1 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "RMSE for current model: 113.94009006155328\n",
      "\n",
      "Iteration 188: 5 layers, 100 neurons, 0.1 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\n",
      "RMSE for current model: 154.9792829338983\n",
      "\n",
      "Iteration 189: 5 layers, 100 neurons, 0.5 dropout, 1 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      "RMSE for current model: 166.3691168169129\n",
      "\n",
      "Iteration 190: 5 layers, 100 neurons, 0.5 dropout, 7 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "RMSE for current model: 140.11038612021218\n",
      "\n",
      "Iteration 191: 5 layers, 100 neurons, 0.5 dropout, 14 time steps.\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "RMSE for current model: 171.8435197344523\n",
      "\n",
      "Iteration 192: 5 layers, 100 neurons, 0.5 dropout, 30 time steps.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "RMSE for current model: 233.81725665626158\n",
      "\n",
      "Best model RMSE: 85.51766536365764\n",
      "\n",
      "Best parameters:Layers=5, Neurons=100, Dropout=0.1, Time step=7\n",
      "\n",
      "Best model found in Iteration: 186\n"
     ]
    }
   ],
   "source": [
    "# Third split (i= 129 to 192)\n",
    "\n",
    "print('\\nThird split')\n",
    "for i, params in enumerate(itertools.product(*param_grid.values()), start=1):\n",
    "    if i <= 2*split_size:\n",
    "        continue     \n",
    "        \n",
    "    if i > total_combinations:\n",
    "        break\n",
    "\n",
    "    n_layers, n_neurons, dropout_rate, time_step = params  # Unpack the parameters\n",
    "    \n",
    "    # Print iteration number, parameter combination, and total combinations\n",
    "    print(f\"\\nIteration {i}: {n_layers} layers, {n_neurons} neurons, {dropout_rate} dropout, {time_step} time steps.\")\n",
    "\n",
    "    # Transform to supervised learning\n",
    "    X_train, y_train = create_dataset(train_data, time_step=time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step=time_step)\n",
    "    \n",
    "    # Reshape input to be [samples, time steps, features] for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    \n",
    "    # Create your LSTM model with the current parameter combination\n",
    "    model = create_lstm_model(n_layers=n_layers, n_neurons=n_neurons, dropout_rate=dropout_rate, time_step=time_step)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=False)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Reshape y_pred to be 1D for RMSE calculation\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"\\nRMSE for current model: {rmse}\")\n",
    "    \n",
    "    # Update best model if the current one is better\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        best_iteration = i\n",
    "# Output the best model and parameters\n",
    "print(f\"\\nBest model RMSE: {best_rmse}\")\n",
    "print(f\"\\nBest parameters:Layers={best_params[0]}, Neurons={best_params[1]}, Dropout={best_params[2]}, Time step={best_params[3]}\")\n",
    "print(f'\\nBest model found in Iteration: {best_iteration}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca840131-5b8c-40bc-be05-f6a372b2fbda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
